{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f566e09",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad75ccd",
   "metadata": {},
   "source": [
    "In this Project, we are going to perform a full unsupervised learning machine learning project on a \"Wholesale Data\" dataset. The dataset refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories\n",
    "\n",
    "[Kaggle Link](https://www.kaggle.com/datasets/binovi/wholesale-customers-data-set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d204b",
   "metadata": {},
   "source": [
    "### Notebook: [MachineLearning_UnSupervised_Fonseca_Leonardo.ipynb](https://github.com/leoaugusto1976/LHL-Unsupervised-Learning-Project/blob/main/notebooks/MachineLearning_UnSupervised_Fonseca_Leonardo.ipynb)\n",
    "\n",
    "> The file contains dedicated code sections for each part below, making it easy to identify and locate each item. Each part is highlighted for quick and convenient reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e57f31",
   "metadata": {},
   "source": [
    "# Part I : EDA - Exploratory Data Analysis & Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c827a5",
   "metadata": {},
   "source": [
    "The given dataset seems to be a grocery sales dataset containing information about various products sold by a grocery store. To perform an exploratory data analysis (EDA) on this dataset, we can perform the following tasks:\n",
    "\n",
    "- Data Import: Import the dataset into a statistical software tool such as Python or R.\n",
    "- Data Cleaning: Check the dataset for any missing or incorrect data and clean the dataset accordingly. This may involve removing or imputing missing data or correcting any obvious errors.\n",
    "Data Description: Generate summary statistics such as mean, median, and standard deviation for each column of the dataset. This will help in understanding the distribution of data in each column.\n",
    "- Data Visualization: Create various visualizations such as histograms, box plots, scatter plots, and heatmaps to understand the relationships and trends between the different variables in the dataset. For example, we can create a scatter plot between the \"Fresh\" and \"Milk\" variables to see if there is any correlation between them.\n",
    "- Outlier Detection: Check for any outliers in the dataset and determine whether they are valid or erroneous data points.\n",
    "- Correlation Analysis: Calculate the correlation between different variables in the dataset to determine which variables are highly correlated and which ones are not. For example, we can calculate the correlation between \"Grocery\" and \"Detergents_Paper\" to see if there is any relationship between these two variables.\n",
    "- Data Transformation: If necessary, transform the data by standardizing or normalizing the variables to make them comparable across different scales.\n",
    "- Feature Selection: Identify the most important features or variables that contribute the most to the overall variance in the dataset. This can be done using various feature selection techniques such as principal component analysis (PCA) or random forest regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd472b2a",
   "metadata": {},
   "source": [
    "# Part II - KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54982ce3",
   "metadata": {},
   "source": [
    "The objective of the analysis is to group similar products together into clusters based on their attributes such as fresh, milk, grocery, frozen, detergents_paper, and delicatessen. To perform the k-means clustering analysis, you will need to pre-process the dataset, determine the optimal number of clusters, initialize the centroids, assign data points to clusters, update the centroids, and repeat until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f48cda",
   "metadata": {},
   "source": [
    "# Part III - Hierarchical Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba2210",
   "metadata": {},
   "source": [
    "Hierarchical clustering is a popular unsupervised machine learning algorithm that is used to identify patterns and group similar data points together in a hierarchy. The algorithm works by iteratively merging or splitting clusters based on a similarity measure until a dendrogram is formed.\n",
    "\n",
    "To perform hierarchical clustering analysis, you will need to pre-process the dataset, determine the optimal number of clusters using techniques such as dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd516495",
   "metadata": {},
   "source": [
    "# Part IV - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cf638",
   "metadata": {},
   "source": [
    "In this section you are going to perform principal component analysis (PCA) to draw conclusions about the underlying structure of the wholesale customer data. Since using PCA on a dataset calculates the dimensions which best maximize variance, we will find which compound combinations of features best describe customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193765ae",
   "metadata": {},
   "source": [
    "# Part V - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc26f00",
   "metadata": {},
   "source": [
    "From the model you developed and the exploratory data analysis (EDA) conducted, generate four bullet points as your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd1c36",
   "metadata": {},
   "source": [
    "- The correlation heatmap is showing the correlation coefficients between different features in the dataset. \n",
    "\n",
    "    - **Grocery and Detergents_paper (0.85):**\n",
    "\n",
    "        A correlation coefficient of 0.85 indicates a strong positive linear relationship between \"Grocery\" and \"Detergents_Paper\".\n",
    "        It suggests that as the spending on groceries increases, there's a high probability that spending on detergents and paper products also increases, and vice versa.\n",
    "        These two categories may have similar purchasing patterns or might often be bought together.\n",
    "\n",
    "    - **Grocery and Milk (0.73):**\n",
    "\n",
    "        A correlation coefficient of 0.73 indicates a moderately strong positive linear relationship between \"Grocery\" and \"Milk\".\n",
    "        It suggests that there's some level of association between spending on groceries and spending on milk products, but it's not as strong as the correlation between groceries and detergents/paper.\n",
    "\n",
    "    - **Detergent_paper and Milk (0.68):**\n",
    "\n",
    "        A correlation coefficient of 0.68 indicates a moderate positive linear relationship between \"Detergents_Paper\" and \"Milk\".\n",
    "        It suggests a somewhat similar trend in purchasing patterns between these two categories but is not as strong as the correlation between groceries and detergents/paper.\n",
    "\n",
    "    These correlations can help in understanding how certain categories of products might be related in consumer purchasing behavior. The stronger the positive correlation, the more likely those categories are bought together or exhibit similar patterns in purchases. It's important to note that correlation doesn't imply causation; it only shows the strength and direction of a linear relationship between two variables.\n",
    " \n",
    " - **K-Means Clustering:** Based on the Elbow method, it's visually evident that the optimal number of clusters, K, occurs around 4 or 5. At this point, the reduction in inertia slows down noticeably, indicating a saturation in cluster improvement. As further increasing the number of clusters doesn't significantly reduce inertia, I've selected K=4 as the optimal number of clusters for my analysis.\n",
    "\n",
    " - **Hierarchical Clustering:** In summary, the interpretation suggests that the clusters are well-separated in the feature space, each with its own distinct characteristics based on the ranges of X-axis and Y-axis values. The visualization indicates that the algorithm successfully grouped the data into distinct clusters based on their spatial distribution.\n",
    "\n",
    " - **PCA:** Interpreting the graphic, adding more components contributes to a higher cumulative explained variance, meaning that more variance in the original dataset is retained as the number of components increases. Generally, a decision is made based on the trade-off between capturing enough variance and minimizing the number of components, aiming to strike a balance to avoid overfitting while retaining the most critical information from the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
